# CudaKernels.cu - Documentaci√≥n

## Estado de Implementaci√≥n: 85% Completado

### Descripci√≥n General
`CudaKernels.cu` implementa kernels CUDA optimizados para aceleraci√≥n GPU en redes neuronales dentro del framework BrainLL. Est√° escrito en CUDA C++ y requiere NVCC para compilaci√≥n.

### Dependencias
- CUDA Toolkit (versi√≥n 11.0 o superior)
- cuBLAS para operaciones de √°lgebra lineal
- cuRAND para generaci√≥n de n√∫meros aleatorios
- cuDNN (opcional) para operaciones de deep learning

### Estructura del Archivo

#### 1. Kernels CUDA B√°sicos
- **`updateNeuronsKernel`**: Actualiza estados de neuronas LIF
- **`propagateSignalsKernel`**: Propaga se√±ales entre neuronas
- **`applySTDPKernel`**: Aplica plasticidad STDP
- **`batchProcessKernel`**: Procesamiento por lotes con transformaci√≥n lineal

#### 2. Kernels CUDA Avanzados
- **`computeAttentionKernel`**: Mecanismos de atenci√≥n
- **`softmaxKernel`**: Normalizaci√≥n softmax
- **`layerNormKernel`**: Normalizaci√≥n de capas
- **`convolution2DKernel`**: Convoluci√≥n 2D
- **`activationKernel`**: Funciones de activaci√≥n (ReLU, Sigmoid, Tanh, Leaky ReLU, GELU)

#### 3. CudaMemoryManager
Gestor de memoria GPU thread-safe con pooling completamente implementado:
```cpp
class CudaMemoryManager {
public:
    static CudaMemoryManager& getInstance();
    void* allocate(size_t size, cudaStream_t stream = nullptr);
    void deallocate(void* ptr);
    void* allocateAsync(size_t size, cudaStream_t stream);
    cudaStream_t createStream();
    void destroyStream(cudaStream_t stream);
    void synchronizeStream(cudaStream_t stream);
    void synchronizeAll();
    size_t getAvailableMemory() const;
    void printMemoryStats() const;
};
```

#### 4. CudaSimulation
Clase principal para simulaciones de redes neuronales en GPU completamente implementada:
- Gesti√≥n completa de memoria GPU
- Ejecuci√≥n s√≠ncrona y as√≠ncrona de kernels
- M√∫ltiples streams para paralelizaci√≥n
- Integraci√≥n completa con cuBLAS/cuRAND/cuDNN
- Profiling de rendimiento
- Soporte para operaciones avanzadas (atenci√≥n, normalizaci√≥n, convoluci√≥n)

#### 5. CudaSimulationFactory
Factory completamente implementado para crear instancias optimizadas de CudaSimulation

#### 6. Funciones de Utilidad
Namespace `utils` completamente implementado:
- Detecci√≥n de soporte CUDA
- Informaci√≥n detallada de dispositivos
- Configuraci√≥n √≥ptima de kernels
- Benchmarking de kernels
- Gesti√≥n de errores CUDA
- Warmup de GPU

### Caracter√≠sticas Implementadas

#### ‚úÖ Completamente Implementadas
- **Kernels b√°sicos**: LIF neurons, STDP plasticity, signal propagation
- **Kernels avanzados**: Attention, softmax, layer normalization, 2D convolution, activation functions
- **CudaMemoryManager**: Pooling de memoria, gesti√≥n de streams, estad√≠sticas
- **CudaSimulation**: Operaciones s√≠ncronas y as√≠ncronas, profiling, m√∫ltiples streams
- **Gesti√≥n de dispositivos**: Detecci√≥n, informaci√≥n, configuraci√≥n
- **Utilidades**: Benchmarking, optimizaci√≥n de configuraci√≥n, gesti√≥n de errores
- **Factory pattern**: Creaci√≥n optimizada de simulaciones
- **Fallback implementation**: Stubs para cuando CUDA no est√° disponible

#### üîÑ Parcialmente Implementadas
- **Soporte multi-GPU**: B√°sico (selecci√≥n de dispositivo)
- **Batch processing**: Implementaci√≥n simplificada
- **Integraci√≥n cuDNN**: Condicional (requiere compilaci√≥n con cuDNN)

#### ‚ùå No Implementadas
- **Soporte multi-GPU avanzado**: Distribuci√≥n autom√°tica de carga
- **Kernels especializados**: Transformers completos, BERT, GPT
- **Optimizaciones de memoria avanzadas**: NUMA awareness, memory prefetching
- **Kernels de entrenamiento distribuido**: All-reduce, gradient synchronization
- **Kernels de precisi√≥n mixta**: FP16, INT8 quantization

### Uso B√°sico

```cpp
#include "CudaKernels.cu"

// Verificar soporte CUDA
if (!brainll::cuda::utils::checkCudaSupport()) {
    std::cerr << "CUDA no disponible" << std::endl;
    return -1;
}

// Crear simulaci√≥n optimizada
auto simulation = brainll::cuda::CudaSimulationFactory::createOptimizedSimulation(1000, 5000);

// Inicializar datos
std::vector<double> potentials(1000, 0.0);
std::vector<double> thresholds(1000, 1.0);
std::vector<double> weights(5000, 0.5);
std::vector<int> sources(5000), targets(5000);

// Copiar a GPU (as√≠ncrono)
auto copy_future = simulation->copyDataToGPUAsync(potentials, thresholds, weights, sources, targets);

// Ejecutar simulaci√≥n
simulation->updateNeurons();
simulation->propagateSignals();
simulation->applyPlasticity(0.01, 20.0, 20.0);

// Operaciones avanzadas
float attention_weights[1000 * 1000];
simulation->computeAttentionWeights(queries, keys, attention_weights, 1000, 64);

// Obtener resultados
std::vector<bool> fired_flags(1000);
simulation->copyDataFromGPU(potentials, fired_flags);

// Ver estad√≠sticas de rendimiento
simulation->printProfilingResults();
```

### Compilaci√≥n

```bash
# Compilaci√≥n b√°sica
nvcc -std=c++17 -O3 -arch=sm_70 CudaKernels.cu -lcublas -lcurand -o cuda_kernels

# Con cuDNN
nvcc -std=c++17 -O3 -arch=sm_70 -DCUDNN_AVAILABLE CudaKernels.cu -lcublas -lcurand -lcudnn -o cuda_kernels
```

### Notas de Rendimiento
- Kernels optimizados para GPUs con compute capability 7.0+
- Uso extensivo de memoria compartida
- M√∫ltiples streams para paralelizaci√≥n
- Configuraci√≥n autom√°tica y adaptativa de bloques/grids
- Profiling integrado para optimizaci√≥n
- Pooling de memoria para reducir overhead de allocaci√≥n

### Limitaciones Actuales
- Soporte multi-GPU b√°sico (sin distribuci√≥n autom√°tica)
- Falta de kernels especializados para modelos transformer
- Sin soporte para precisi√≥n mixta (FP16/INT8)
- Gesti√≥n de memoria NUMA no implementada
- Falta de kernels para entrenamiento distribuido